{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To concatenate all txt files in a directory into one big txt file,\n",
    "# navigate to the right directory and run this command in terminal:\n",
    "#           cat *.txt > name_of_new_doc.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "# texts is expected to be a list of filepaths to text docs\n",
    "def make_dictionaries(text_path):\n",
    "    \n",
    "    file_string = \"\"\n",
    "    \n",
    "    with open(text_path, 'r') as f:\n",
    "        file_string += f.read()\n",
    "    file_string = file_string.lower()\n",
    "    all_chars = sorted(list(set(file_string)))\n",
    "    \n",
    "    # Get vocab set and make dictionaries\n",
    "    int_to_char = {i: c for i,c in enumerate(all_chars)}\n",
    "    char_to_int = {c: i for i,c in enumerate(all_chars)}\n",
    "\n",
    "    vocab_length = len(all_chars)\n",
    "    \n",
    "    def char_to_embed(char):\n",
    "        em = np.zeros((1, 1, vocab_length)).astype(np.float32)\n",
    "        em[0,0,char_to_int[char]] = 1.0\n",
    "        return em\n",
    "    \n",
    "    return int_to_char, char_to_int, char_to_embed, vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_generator(char_to_int, vocab_length, text_path='all_crime_novels.txt', batch_size=100, time_steps=100):\n",
    "    \n",
    "    text = \"\"\n",
    "    with open(text_path, 'r') as f:\n",
    "        text += f.read()\n",
    "    text = text.lower()\n",
    "    \n",
    "    text_length = len(text)\n",
    "    \n",
    "    id_length = text_length-time_steps-1\n",
    "    \n",
    "    while(True):\n",
    "\n",
    "        X_data = np.zeros((batch_size, time_steps, vocab_length)).astype(np.float32)\n",
    "        y_data = np.zeros((batch_size, time_steps, vocab_length)).astype(np.float32)\n",
    "        for j in range(batch_size):\n",
    "            # Randomizing the input batches is a good idea\n",
    "            i = random.randint(0,id_length)\n",
    "            # One_hot encode X\n",
    "            X_ints = [char_to_int[char] for char in text[i+j:i+j+time_steps]]\n",
    "            X_data[j, np.arange(time_steps), X_ints] = 1.0\n",
    "            # One_hot encode y\n",
    "            y_ints = [char_to_int[char] for char in text[i+j+1:i+j+time_steps+1]]\n",
    "            y_data[j, np.arange(time_steps), y_ints] = 1.0\n",
    "\n",
    "        yield(X_data, y_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(input_data, init_value, in_size=87, out_size=87, batch_size=100, lstm_size=512, num_layers=3, drop_prob=0.5):\n",
    "    \n",
    "    with tf.variable_scope('lstm'):\n",
    "        # LSTM\n",
    "        cells = []\n",
    "        for i in range(num_layers):\n",
    "            cell = tf.contrib.rnn.BasicLSTMCell(lstm_size, forget_bias=1.0, state_is_tuple=False)\n",
    "            cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=drop_prob)\n",
    "            cells.append(cell)\n",
    "        lstm = tf.contrib.rnn.MultiRNNCell(cells, state_is_tuple=False)\n",
    "\n",
    "        outputs, lstm_new_state = tf.nn.dynamic_rnn(lstm, input_data, initial_state=init_value, dtype=tf.float32)\n",
    "\n",
    "        # Feed-Forward layer on top\n",
    "        W = tf.Variable(tf.random_normal((lstm_size, out_size), stddev=0.01))\n",
    "        B = tf.Variable(tf.constant(0.1, shape=[out_size]))\n",
    "\n",
    "        outputs_reshaped = tf.reshape(outputs, [-1, lstm_size])\n",
    "        model_output = tf.add(tf.matmul(outputs_reshaped, W), B)\n",
    "    \n",
    "    return model_output, lstm_new_state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN_WRITER:\n",
    "    \n",
    "    def __init__(self, in_size=87, out_size=87, num_layers=3, lstm_size=512):\n",
    "        \n",
    "        self.output_path = \"model\"\n",
    "        \n",
    "        if not os.path.exists('model'):\n",
    "            os.mkdir('model')\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.lstm_size = lstm_size\n",
    "        self.in_size = in_size\n",
    "        self.out_size = out_size\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, None, self.in_size), name=\"input\")\n",
    "        self.lstm_init_value = tf.placeholder(tf.float32, shape=(None, self.num_layers*2*self.lstm_size), name=\"lstm_init_value\")\n",
    "        \n",
    "        self.y = tf.placeholder(tf.float32, shape=(None, None, self.out_size), name=\"ground_truth\")\n",
    "        y_batch_long = tf.reshape(self.y, [-1, self.out_size])\n",
    "        \n",
    "        self.drop_prob = tf.placeholder(tf.float32, name=\"drop_prob\")\n",
    "        \n",
    "        self.lstm_last_state = np.zeros((self.num_layers*2*self.lstm_size,))\n",
    "        \n",
    "        out, self.next_lstm_state = create_model(self.X, self.lstm_init_value, in_size=self.in_size, out_size=self.out_size, num_layers=self.num_layers, lstm_size=self.lstm_size, drop_prob=self.drop_prob)\n",
    "        \n",
    "        self.loss = self.get_loss(out, y_batch_long)\n",
    "        \n",
    "        self.final_outputs = tf.reshape(tf.nn.softmax(out), (1, self.out_size,))\n",
    "        \n",
    "        \n",
    "    def get_loss(self, logits, labels):\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def save(self, sess, model_path):\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        return save_path\n",
    "    \n",
    "    def restore(self, sess, model_path):\n",
    "        \n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, model_path)\n",
    "    \n",
    "    def predict(self, model_path, int_to_char, char_to_embed, restore=True, prefix=\"The \", num_steps=500, weight=False):\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        \n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(init)\n",
    "            \n",
    "            if restore:\n",
    "                self.restore(sess, model_path)\n",
    "            \n",
    "            out_string = prefix\n",
    "            \n",
    "            prefix = prefix.lower()\n",
    "            \n",
    "            init_value = np.zeros((1,self.num_layers*2*self.lstm_size))\n",
    "            \n",
    "            # Input prefix\n",
    "            for i in range(len(prefix)):\n",
    "                \n",
    "                out, next_lstm_state = sess.run([self.final_outputs, self.next_lstm_state], feed_dict={self.X: char_to_embed(prefix[i]), self.lstm_init_value: init_value, self.drop_prob: 1.0})\n",
    "                init_value = next_lstm_state\n",
    "            \n",
    "            # Continue generating\n",
    "            for i in range(num_steps):\n",
    "                \n",
    "                if (weight):\n",
    "                    out *= out\n",
    "                    out /= np.sum(out)\n",
    "                    \n",
    "                gen_char = np.random.choice(range(self.out_size), p=np.squeeze(out))\n",
    "                out_string += int_to_char[gen_char]\n",
    "                \n",
    "                out, next_lstm_state = sess.run([self.final_outputs, self.next_lstm_state], feed_dict={self.X: char_to_embed(int_to_char[gen_char]), self.lstm_init_value: init_value, self.drop_prob: 1.0})\n",
    "                init_value = next_lstm_state\n",
    "                            \n",
    "        return out_string\n",
    "    \n",
    "    def train(self, data_generator, model_path=None, learning_rate=0.008, batch_size=100, training_iters=1000, display_step=100, restore=False):\n",
    "        \n",
    "        if model_path == None:\n",
    "            model_path = os.path.join(self.output_path, 'rnn.ckpt')\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.learning_rate, 0.9).minimize(self.loss)\n",
    "#         self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        with tf.Session() as sess:\n",
    "            \n",
    "            sess.run(init)\n",
    "            \n",
    "            if restore:\n",
    "                self.restore(sess, model_path)\n",
    "            \n",
    "            print(\"Beginning training\")\n",
    "            \n",
    "            total_loss = 0.0\n",
    "                \n",
    "            for i in range(training_iters):\n",
    "                \n",
    "                x_batch, y_batch = next(data_generator)\n",
    "            \n",
    "                init_value = np.zeros((batch_size, self.num_layers*2*self.lstm_size))\n",
    "        \n",
    "                loss, _ = sess.run([self.loss, self.optimizer], feed_dict={self.X: x_batch, self.y: y_batch, self.lstm_init_value: init_value, self.drop_prob: 0.5})\n",
    "                \n",
    "                total_loss += loss\n",
    "                \n",
    "                if ((i % display_step == 0) and (i != 0)):\n",
    "                    print(\"Avg loss at iteration %d = %f\" % (i, (total_loss/display_step)))\n",
    "                    total_loss = 0.0\n",
    "                \n",
    "                \n",
    "            save_path = self.save(sess, model_path)\n",
    "        \n",
    "        return save_path\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_path = 'all_crime_novels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char, char_to_int, char_to_embed, vocab_length = make_dictionaries(text_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_gen = data_generator(char_to_int, vocab_length, 'all_crime_novels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcb9664a908>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbf7b7dcf8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcb8ffc9978>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "my_rnn = RNN_WRITER(in_size=vocab_length, out_size=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_path = 'model/rnn.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/rnn.ckpt\n",
      "Beginning training\n",
      "Avg loss at iteration 250 = 1.335674\n",
      "Avg loss at iteration 500 = 1.345187\n",
      "Avg loss at iteration 750 = 1.322052\n",
      "Avg loss at iteration 1000 = 1.318800\n",
      "Avg loss at iteration 1250 = 1.319542\n",
      "Avg loss at iteration 1500 = 1.308416\n",
      "Avg loss at iteration 1750 = 1.319194\n",
      "Avg loss at iteration 2000 = 1.314571\n",
      "Avg loss at iteration 2250 = 1.303299\n",
      "Avg loss at iteration 2500 = 1.292210\n",
      "Avg loss at iteration 2750 = 1.305736\n",
      "Avg loss at iteration 3000 = 1.302133\n",
      "Avg loss at iteration 3250 = 1.327167\n",
      "Avg loss at iteration 3500 = 1.332801\n",
      "Avg loss at iteration 3750 = 1.304668\n",
      "Avg loss at iteration 4000 = 1.308191\n",
      "Avg loss at iteration 4250 = 1.296033\n",
      "Avg loss at iteration 4500 = 1.293242\n",
      "Avg loss at iteration 4750 = 1.281998\n",
      "Avg loss at iteration 5000 = 1.313288\n",
      "Avg loss at iteration 5250 = 1.286084\n",
      "Avg loss at iteration 5500 = 1.303965\n",
      "Avg loss at iteration 5750 = 1.297595\n",
      "Avg loss at iteration 6000 = 1.283477\n",
      "Avg loss at iteration 6250 = 1.318651\n",
      "Avg loss at iteration 6500 = 1.286549\n",
      "Avg loss at iteration 6750 = 1.320575\n",
      "Avg loss at iteration 7000 = 1.307795\n",
      "Avg loss at iteration 7250 = 1.312847\n",
      "Avg loss at iteration 7500 = 1.306900\n",
      "Avg loss at iteration 7750 = 1.308762\n",
      "Avg loss at iteration 8000 = 1.296142\n",
      "Avg loss at iteration 8250 = 1.303994\n",
      "Avg loss at iteration 8500 = 1.289764\n",
      "Avg loss at iteration 8750 = 1.289659\n",
      "Avg loss at iteration 9000 = 1.300812\n",
      "Avg loss at iteration 9250 = 1.312011\n",
      "Avg loss at iteration 9500 = 1.305648\n",
      "Avg loss at iteration 9750 = 1.287420\n"
     ]
    }
   ],
   "source": [
    "save_path = my_rnn.train(data_gen, model_path=save_path, learning_rate=0.0003, training_iters=10000, display_step=250, restore=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbb372c0f0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcb5eed19b0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbb372c278>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "my_rnn = RNN_WRITER(in_size=vocab_length, out_size=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/rnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "output = my_rnn.predict(model_path=save_path, int_to_char=int_to_char, char_to_embed=char_to_embed, restore=True, num_steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The aid from white with with the compiel, over that shopt whyrerem fast it wamped eyes pluce yeaon.\"\n",
      "\n",
      "she tordered goap a gravto-kard. her was grittenmen stupled\n",
      "a cluced arthor in sharply,\n",
      "he wesd't to halks to the stresn. the ploblos\n",
      "colded and stupked\n",
      "a luttle beciered the faght under his glaich kadn't pusted nose were eches weite\n",
      "trigch\".a\"lockicatseich agay.\"\n",
      "\n",
      "breather think on the lew,\" man carably lalthyly one cur\n",
      "and for the littlesalace, as yeu all this you furher the wering mrs. jly rust c\n"
     ]
    }
   ],
   "source": [
    "# After 3000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pemples and gray size, turned the desk and going for clenetch\n",
      "at the mamento boy this tied, the heavy, whole it, eyes over on the mowe in the\n",
      "girl.\n",
      "\n",
      "they were late was who with a drugstoreed large racket. they were thinging\n",
      "to wald himing along the elevator, floor behind by that was to be even wadean. we got up to sceps a menshand, crafing on the lailing. i know, john that.”\n",
      "\n",
      "dalmas said: “what could meas?”\n",
      "\n",
      "he didn’t aramn back to the knobs that fastened for around on his eyes. he\n",
      "got a\n",
      "window \n"
     ]
    }
   ],
   "source": [
    "# After 23,000 iterations\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brush and come to him\n",
      "by a wold brush.\n",
      "\n",
      "\"it's a huary.\"\n",
      "\n",
      "i said. \"the night strike\n",
      "halfs,\" i said. \"i lay at the cop and don't like it.\"\n",
      "\n",
      "\"that's captains it think, we wouldn't think he would been have not at lending about them.\"\n",
      "\n",
      "\"how she is a lot of that\n",
      "about him trand. he's still been backs while i seemed to\n",
      "help the\n",
      "cold\n",
      "knows and looked for the\n",
      "left hundred kid.\n",
      "\n",
      "\"he was\n",
      "still to go there. we nicked because he came as head here address this facts. howed you speak. it figured it was known r\n"
     ]
    }
   ],
   "source": [
    "# After 33,000 iterations\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The girl opened a chair back and unuiled and\n",
      "not coming from his glass.\n",
      "\n",
      "reno did it,\n",
      "line as rose and living some tramp in face. he thought they were working for one right that had a clean curtain of literal willsson has been in marry.\n",
      "\n",
      "he just didn’t make down the\n",
      "alley sibred hirrible enough\n",
      "to attle the pull of fate in daon as if always felt the world was doing the others. the one of\n",
      "a refice. he had moved\n",
      "away, in something that could and between the\n",
      "pursers outside me. by a name masters. no table appeared to cover them. the sour ontachiness.\n",
      "\n",
      "“miss building is it?”\n",
      "\n",
      "“there were a red fight to give a goudy luck of this enough, that\n",
      "is—say it\n",
      "says\n",
      "about him, but the mitt had said which was going to be\n",
      "which the chief is pupping in am\n",
      "rek burning world, picked up and had you understend. the\n",
      "chauffeur could see much cut of whisper on0irent a new idea was\n",
      "only\n",
      "sitting by and that not the doke he liked and kig dark in girl or about his eyes.\n",
      "\n",
      "unless he nodded a cartain of the called lips by the reno starter.\n",
      "\n",
      "a ilalent proves\n",
      "of a pink right arming right life and shakes aight sign for it, there\n",
      "that don’t k instind in we had goes over around machwains.\n",
      "\n",
      "the curb out at the pretty dinders in five minutes, and through his picture. anything is about a\n",
      "bill. i\n",
      "understand rolff\n",
      "shoved old a. he did the rounds to love, nodded, thinking his\n",
      "eyes put a short work down with his forehead and pagged the air on it, a bank gun in the back hand. a\n",
      "humined city top scotch near his deep safe in gizely tharticisting, but the surfriends was tighted around and bastree before he had been strick in them.\n",
      "\n",
      "the house, pretended he did stuck a back that the\n",
      "cigarette. he except while it don’t have was a cross tlime.\n",
      "\n",
      "a\n",
      "office was doing the way i needs it. \n",
      "                                          one this man who at all he\n",
      "had bothered for it.\n",
      "\n",
      "                                                   err\n",
      "\n",
      "mefal street art become to the s mocking face has to get\n",
      "a sprang and his name, in a harn.\n",
      "\n",
      "in a condcial interest was right. miles came in before enough lave country.\n",
      "\n",
      "it limchined\n",
      "story and myself about. the murder took problems and given them no. he looked out of the hall\n",
      "and pasting side of the police, which had a toet alave against the face.\n",
      "\n",
      "i stood nor and almost in his face. burned the table enautions amigitionless voice without a entare-esgable floor under\n",
      "town. the side\n",
      "eas bemert curded and him along and that was the\n",
      "bottle of schousune i became skeating noonan with a moment.\n",
      "\n",
      "the corner did not stood the gloss on a druster reading voice deings on at me, shifted his right face. i made a markde, over a man was waiting moved at its and reported as if he\n",
      "might think this is it. they be divorced spade that never cupped his gray and hotyeat, some of them unevened the man looked as driver sideways had in two thousand more and he whispered as it suggested in a voice in a voice, and whisper, debinations in eight.\n",
      "\n",
      "i stood at rest. “he held to do that, hoen,” i said, a hollow an\n",
      "out. she delygely and tilted\n",
      "a moterusants, to\n",
      "action,\n",
      "and bounced on without vicious. to put people out of the read.”\n",
      "\n",
      "the distant barders were casually to be coming up, and langule all the floor and saw me out of the table.\n",
      "\n",
      "the stugg that came through an outing not to touch out. they do know you can be there what let a pale of the talk jokity, or being the shot tauting in it. you say anything or it is a moment stuff, had very not epperrathing\n",
      "somewhere lobs, a dumm from with every\n",
      "double drugstants. all they comes him to probably take no\n",
      "trity piece, or\n",
      "enfire that\n",
      "they couldn’t know the braenficulars of good and broken other brandies akeable until from cueaman had\n",
      "believed it. he carefully empty on a tall dimme tail, put the dapping mouth, but he is near the\n",
      "provems of a nice croaked night, bleed esartly as fire ratter. the front ten himself not not wrote. he wunged into a wrodie till, a machual note of amusement on a police into hers, and a black man against the other morning. he leaned forward as afraid of the world can\n",
      "be\n",
      "looking at the streets and be, go for them. none of it was sitting to want to take him\n",
      "out of here.\n",
      "\n",
      "macscaily is a cool eyes at the dead last letter. he was out with a truth, and sound thick times in black\n",
      "softad before he could try\n",
      "for the loose pocket. she\n",
      "stood up, and wrenched which\n",
      "a muscle and warmers. it dropped in her right one sourly as a rust. his rocker killed mitch. we had who shoved a little osl shade a couple of more\n",
      "than a head.\n",
      "\n",
      "the chimless lostered out of cool thugrauses. the unpersonville whisper was to be. passed\n",
      "there and scratging us my forehead both hands out of the curtain?\n",
      "reader. dan thin small\n",
      "chargea-girl into my arm and disappeared and telling martaly sick both. the kitchen probopt sure it was pheding at the rumbleld white card. a\n",
      "decided had looked at his name in a lamge of rower and as budmed. the clieis man who could eciden shot him around realing from dicks, his teeth is killed character of nepstor\n",
      "big u\n"
     ]
    }
   ],
   "source": [
    "# After 43,000 iterations\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The body was gently. she went to the gun on his top. there was something any cop.\n",
      "\n",
      "“come in.”\n",
      "\n",
      "he sipped it out last night, and mired, stiffened, went across the door. “you\n",
      "go most of the order of the steve. so they had lipped it in a noisy. steve.”\n",
      "\n",
      "bock of elihu was alteration of garaganis occupes. in it that\n",
      "forecanelil or somebody in her head to some sound with that. i believe it, i can\n",
      "give it noos.\n",
      "i’m going to talk. how do you see what i wouldn’t get away. what else still points a home. i wouldn’t know’s.”\n",
      "\n",
      "steve said: “what you don’t don’t\n",
      "like a copper and out of noshical, don’t let the king of the gun, bill to the as don’t pick up a\n",
      "bean-haired flatmere looked like the gray cards in breathing and thinks there’s\n",
      "nothing to do it?”\n",
      "\n",
      "“of course.”\n",
      "\n",
      "“jack upstairs reading a look at that door once. here.”\n",
      "\n",
      "he looked at the torn blocks and stood motionless. really had taken one the last drivers to.\n",
      "\n",
      "he took out it. a week that just empty stuff, but it was a man that\n",
      "means it’s fisting with\n",
      "delicate men, with a\n",
      "guy. he was doing leives up read the trip inside. but steve’s feet neither, closet, but not a taying, not. my reader was in lobby, go to suspender too. we real like two hundred on here and told\n",
      "a totion of jeed gun over to him if\n",
      "and, sam. i post my danter of the flesh with it. i can’t go to bed with me, just my client.\n",
      "\n",
      "he better do with her to\n",
      "never kill her?”\n",
      "\n",
      "“i don’t know he’s agatha\n",
      "sure thats have now.”\n",
      "\n",
      "steve took him in and drank. her eyes had a little like stuff. his start she shook his head said enough. she didn’t seem to mind you some of it.”\n",
      "\n",
      "it took the head back inside the matal top of the bed as if she\n",
      "issee about if he\n",
      "could leave that. it’s not the desk. just glass death. you will i have put a black colored, mo trying to our back in the\n",
      "palm. has a look.\n",
      "you is been coming out now.”\n",
      "\n",
      "steve said: “you try there?”\n",
      "\n",
      "the rest of the steve said coming agatha, stood\n",
      "in some yound like big\n",
      "man, and there’s both like that in the corner, still across the matter. go out at my feet,\n",
      "sovely home. he\n",
      "could have looked with his faper. you’re a stuff again. maybe i’m burned,\n",
      "it’s what i never get myself. and there’s a round red guy and he on big sounds come on night. know what you should not prove it. that wouldn’t please. you don’t know that. he always night\n",
      "with it. i don’t know where that’s\n",
      "fast. you wouldn’t be cream\n",
      "loudly, like he becomist the lady and should get well. i could get to let the neatly nickel. but it was a possible futs to never know my clerks. that were\n",
      "clean. he had black on it. and why didn’t you know how you couldn’t never shoe a heavy. what is the faor time? i didn’t know whether they shail. his running gun. i is other key over. was he that behind\n",
      "some your hand. i’m sorry to no saying you will drink.”\n",
      "\n",
      "“well, you put him you poked told me for police,\n",
      "of course what not be. i suppose go out there’s a bad. i don’t know anybody’s saved blind.”\n",
      "\n",
      "“out a copper\n",
      "string and he’ll of him—just then, how’s jutt to do they took the sing down a top too. he was back on\n",
      "her here. i was hardly bought. he’s douch, steve. cost that,” i said, “too senting here. there was his vest curling the\n",
      "street, something. on it. she still came through him, was well tell that, couldn’t.”\n",
      "\n",
      "she let him click from his hand. he drove me in. bright. only\n",
      "he was in\n",
      "now. i couldn’t have contained the copper,” i falled, her finger stepped in the door and shut the stupid slaps. leopardi said: “you have\n",
      "trotrel the bottle. then he were hiding at band.\n",
      "we got the guy in the book. and he can after that on a gun, more of that?”\n",
      "\n",
      "“talk it now.”\n",
      "\n",
      "“who did it play here,” she said too. “probably the leg said into a brand shorts on her—that’s establish up, company and fell down the station. have you five one. get your block and talk about what ralfoquie bandoins we did.\n",
      "they ever is just a\n",
      "very good faith in his record.\n",
      "that’s even if she takes in my big rest for\n",
      "me, to take your nine. don’t there\n",
      "handpriving a cheek in my man, do you talks at two dollars. this is a trick?”\n",
      "\n",
      "steve drank the tower end of the living room. i didn’t look at the\n",
      "door, then shook the fingers and smiled back as if too many voice.\n",
      "\n",
      "steve took the brown hand. “i don’t like to let him find a suiting hick and convinced more\n",
      "companeless. sir, steve. from nod on\n",
      "a rivem\n",
      "on.\n",
      "you py my wrong.”\n",
      "\n",
      "“then he got a mied for the good\n",
      "night, does it come out again. what of the osgect loukhoy?”\n",
      "\n",
      "ma three comeed friends moved on you. so he can’t convince me following about that. sure you suppose.”\n",
      "\n",
      "the girl looked at himself and stedped a eyes gill and as he looked at her to get out of silent. then he removed\n",
      "his pocket and was silent he wouldn’t have a innocent slow altogether.\n",
      "\n",
      "he made that drink against the steve?”\n",
      "\n",
      "“have to look look she are.\n",
      "uvel, had to do.”\n",
      "\n",
      "the swift leopardi nodded. “yes. but i didn’t think she’s a man chuggy, mr. dockers for there, put it with me\n",
      "that that sand,” she said, “and in the pajamas were siited for the end of it. we pulled back \n"
     ]
    }
   ],
   "source": [
    "# After 63,000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The state. cigarettes. it stopped back.\n",
      "\n",
      "“heh. but” and that let him alenave left. i think you know that is even patient, could\n",
      "ed aon believe that.”\n",
      "\n",
      "he pointed. “gutman’s nails like it just moint.\"\n",
      "\n",
      "\"that’s why he was\n",
      "a guard, damn book and i don't know a guy could get would not go over against the chance,” one is to watch it. it’s drinking\n",
      "to push out it laight.\n",
      "\n",
      "they went on right against the books, with my lohic little push that no chief, you think the frest in delieine makes me probably really near? my guilty bundles. he could do his short around the rug. what happened to my importance for us. the musace sweat got out to his asin. the boy had probably signed his teeth into it, and\n",
      "got up of colors down other window was gloved. no scressed captoon-looking\n",
      "apartment eyes. he was still\n",
      "a stelp. the pocket floating behind me until he began to chepe from the floor night in your atfers.\"\n",
      "\n",
      "he said: “hello, hr. is the way to one man they are running plenty around my\n",
      "fingers.\"\n",
      "\n",
      "i looked at me spade.\n",
      "\n",
      "he stared at him as if degingering, looking down at the name of\n",
      "it and\n",
      "finished his big mind. the bird said:\n",
      "\n",
      "“not restaurant came to her, so you looked out of\n",
      "velbal color, copper by all over the car and tell iterby was open mimi. let’s go to the way i saw him. sorry.”\n",
      "\n",
      "you’re very clean de\n",
      "things, hohy attention everything.”\n",
      "\n",
      "spade said: “only where waued it would see her\n",
      "hunting on let it get as if a dead of you\n",
      "she thought?\"\n",
      "\n",
      "\"i can’t have them as you chief see\n",
      "you know what you’re all together. don’t you a fact?”\n",
      "\n",
      "“he knew they opened it back where they bepcaired?” she said, “that pretty craar the things are dressed. okay, did you.” he could have had to separl the flower out. “kid it with,” he said. \"just take it luve.\"\n",
      "\n",
      "he had an envelope down.\n",
      "\n",
      "i looked at it and couldn’t have said de three-cut up and protected my feet in the other side of the bathroom. the big lights were no automatics\n",
      "of\n",
      "small short flash\n",
      "and connection with a bort of\n",
      "coffee.\n",
      "\n",
      "\"a valuais was any coming out\n",
      "in it.”\n",
      "\n",
      "“what’s the retorm?\"\n",
      "\n",
      "he line down and staid, then got out of his hair. “it’s a pig of the sleep, darling. is it kadded?”\n",
      "\n",
      "“well, sir, and\n",
      "the hack stuff climbed into the phone.”\n",
      "\n",
      "he went powder,” i said to the wall.\n",
      "\n",
      "he lifted his hand on the corner of the boy of the maid to the dishasbight of a clike face,\n",
      "went out. “no. you took the cut the attempt\n",
      "to here you’d seen what there was i said fifty-minutes\n",
      "sure.\n",
      "\n",
      "it wasn't a lot to the kitchen, exactly what the\n",
      "heart was shot\n",
      "with empty or a hell\n",
      "dolate. hello’s me. i'll have plenty enough to make you.”\n",
      "\n",
      "“sure,” he said with that old bar. “anything woild only say, she knew what i stopped. marriott deserved one drop of jounced?”\n",
      "\n",
      "“no. i probably i knew anything that\n",
      "seacched him\n",
      "a lot, but it’s a boecard.\n",
      "he\n",
      "foods wondering anything about giy.\"\n",
      "\n",
      "\"spend here and huh? she was calling anything\n",
      "expecting.”\n",
      "\n",
      "he put it down on a feet up and grinned at me and sripped a cigarette, his thick cloth to be who can\n",
      "make dorothy\n",
      "talked in the green publicity five\n",
      "enough\n",
      "for sweat.\n",
      "\n",
      "“and you’re too till. i know it was waut.” he said: “that’s when i said, and don’t see dead\n",
      "sixty deal she had been\n",
      "when he bent and finish his dinah brand, it was a couple of public\n",
      "really brigid o’shaughnessy.\n",
      "\n",
      "“get it to deep, politician than you’ve got to\n",
      "never have been talked to mr. edece went out. in the last time they stay around that\n",
      "seovem record he had parked slowly at the inner end. the girl had\n",
      "been in his apartment, caar along. he knew he was with any feelings and don’t didn't remember a poborry job, whisper \n",
      "i can’t see information?”\n",
      "\n",
      "“the cop. i couldn't be a aw last night i eleven where you went at all. i\n",
      "panal have you. it’s ball right. that’s like they’m a\n",
      "few exactly service,” i said.\n",
      "\n",
      "cairo slugged it to my shoulder, his face were check, her hands, learing\n",
      "around his lip.\n",
      "\n",
      "she looked at me with a tip and married line desk, said:\n",
      "\n",
      "“chief\n",
      "smart the girl to amless and a name idea,” he said, “but he gets in a heol had started right in we ain’t really idea at all. you’re a given a hard.\n",
      "\n",
      "stemme that because that’s or he wasn’t even your letter have a dial stared at it with nobody\n",
      "gets on. i saw him cowpnenix. the creat had so the prowl come out of the time, even to profess at least a fifty ewusion. what made what they seem once. i wouldn't know how they were made\n",
      "down on your accept of complain. his eyes were drunk cigaring hands. i had a detective spatch, kind to it? but it\n",
      "was that denagulass on know like it, the\n",
      "night at pant. we at what he would no\n",
      "before if he had make corners that\n",
      "got his feet. i say we could find out he said. when anybody got with his breath so i talked to for his time.\n",
      "\n",
      "ronal damn thing about were my rust\n",
      "city with me would be any\n",
      "way to come out.\n",
      "\n",
      "he thought any more than what was regular mine. it was just right.”\n",
      "\n",
      "“sure. i’m coming to me. she doesn’t been that carreed him. it was that herin in the stiol. tim. spade’s a memory, have you?” he asked.\n",
      "\n",
      "i looked at me softly.\n",
      "\n",
      "we wo\n"
     ]
    }
   ],
   "source": [
    "# After 75,000 iterations\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbb0703240>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbb07034a8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x7fcbb0703630>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "my_rnn = RNN_WRITER(in_size=vocab_length, out_size=vocab_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/rnn.ckpt\n"
     ]
    }
   ],
   "source": [
    "# This time weight the probabilities we're sampling from a little bit\n",
    "# so that the higher probabilities will be chosen even more than they\n",
    "# would have normally and the lower probabilities even less\n",
    "output = my_rnn.predict(model_path=save_path, int_to_char=int_to_char, char_to_embed=char_to_embed, restore=True, num_steps=5000, weight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The car sounded back at the desk. he set it close to the top of the corner of the corner and stared at him.\n",
      "\n",
      "“you say the world is a fact that i can make it to her with him in the car and then go to the big man and they want to do anything. i heard you think it’s a fat man that played it to me. i said the guy who didn’t want a couple of cards, and the stuff is a big car and the shop and the bedroom was a lot of pretty sort of car out of the sofa and passed a cigarette on the desk.\n",
      "\n",
      "“i don’t know anything. i is for me on the street. i got a little pale of it. i’m looking at and what are you made my and the real cut the story the right to call me anything. and the tough drink was the trick. they had been funny in the truth. i didn’t know where you seem to have to have the night he could see him and the taxi hotel in the man don’t like that in the interesting job.\n",
      "\n",
      "the man who had some of them will expect him to be all he was manner with the one and the old man was about the one that was something about anything to think of the kind of beautiful big room and was the time to get away from the\n",
      "first shiny line.\n",
      "\n",
      "he stood bored and said: “the police was seen his teeth and he’s a small evening that\n",
      "she was a lot of sound of a sharp pencil and the big other way to see her in a way he didn’t know how i could take it in the desk and then with a wide thick end of the corner.\n",
      "\n",
      "he leaned back and took a gold second piece. he put it out to the corner of his side.\n",
      "\n",
      "“sure. the street don’t do the hell of his green, the way the car moved to her. i didn’t know what i had to go out and be shooting around in the pale and i can give you good that they might be all the tall ball and his in his chin. they were handed and think it was a little money and say the thing was some pictures and the sound of the next tray. i didn't know what i was a small bank back in the floor.\n",
      "\n",
      "“oh, what was the work for you and he was the first time anything to do that the fair to the bright end of the way.”\n",
      "\n",
      "“he was the probably for a lot of little distance and the gun in the other one that was a little any of the man and he was a detective silly and the big man said: “well, well, if you know what it was the night while you can put the boys have been here. and i wouldn't know what it was right. he\n",
      "was still being made on the bed and the with me and show the guy with the contents and a guy with a steps for a moment and then went through a body of stone. he said: “the spring to think it was the girl before he didn’t know what i had anything to do with the booth and the world who was the back steps in the other side of the corner and sat down and the desk was not still and she said: “what was you sore. i think you mean when the door was all the pair of the book was careful. i can wait as if they could see him and a sick too much who said i got to do it and put the outside of his lips and started to start a handkerchief and said: “you didn’t know. it was a thing in the first street. i should tell me what i had a couple of minutes when i was as the funny thing. he was like a story when he was a good world of hollywood and got the second the least things down the girl and what it doesn't come in over the back of the bed and went out and grinned at me without sound and closed the door straight and stood there in the name and put his hands in the labily and stared at me and the boy became good and shadowed at him down the room and said: “it’s all the man was a stack to me. i was coming up to the ball of the wall and stood up and came into the wood, with a lot of bottles of the car and said: \"i think you want to go to the one of the way you’re the bed and don’t know what you have to be many to the car and he was a put the particular window. the people were on the gat and suppose he can’t find it any expression of business of the day. it comes and then we were something to take a sort of full of the hotel to the door with his side of his hand. he took his hand out of his hand. he said: “and i have a guy who doesn't make that thing i’ll inside the door and the boy were when i was a big bar to a file of the fine door. i told the arm of the car and took a sharp business door open and the sharp eyes were slightly and a shirt of a long time i didn’t anything about the soft man. he shook his head and went over to the glass of the desk and opened the door and said in a soft table with a suoperiea and his eyes were hard and pug a cigar of the old man of the face of his chest, and stared at her and the tall man went out of his head. she said: “i’m all right, but they don’t know he had a standing in the living-room that was the kind of mind and i don’t care a dozen people the pass was a hard and that they would be out. i got a little completely with a little more than a big man.\n",
      "\n",
      "“she says you are told me about the stuff in the breakfast of man and i don’t know what you say that you said he was all the house and which you want to like to be a particular man of my name. i wa\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted result has fewer spelling mistakes but less variety and is more repetitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
